{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Meent Tutorial 2\n",
    "Gradient and Optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import time\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import meent\n",
    "from meent.on_jax.optimizer.loss import LossDeflector\n",
    "from meent.on_jax.optimizer.optimizer import OptimizerJax"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "backend = 1  # JAX\n",
    "\n",
    "# common\n",
    "pol = 0  # 0: TE, 1: TM\n",
    "\n",
    "n_I = 1  # n_incidence\n",
    "n_II = 1  # n_transmission\n",
    "\n",
    "theta = 20 * jnp.pi / 180\n",
    "phi = 50 * jnp.pi / 180\n",
    "\n",
    "wavelength = 900\n",
    "\n",
    "thickness = [500.]\n",
    "period = [1000., 300.]\n",
    "\n",
    "fourier_order = [4, 2]\n",
    "\n",
    "type_complex = jnp.complex128\n",
    "\n",
    "grating_type = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "ucell_1d_s = jnp.array([\n",
    "    [\n",
    "        [0, 1, 0, 1, 1.1, 0, 1, 0, 1, 1, ],\n",
    "    ],\n",
    "], dtype=jnp.float64) * 4. + 1.  # refractive index\n",
    "\n",
    "ucell_2d_s = jnp.array([\n",
    "    [\n",
    "        [0, 1, 0, 1, 1, 0, 1, 0, 1, 1, ],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, ],\n",
    "    ],\n",
    "]) * 4 + 1.  # refractive index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Gradient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "mee = meent.call_mee(backend=backend, grating_type=grating_type, pol=pol, n_I=n_I, n_II=n_II, theta=theta, phi=phi, fourier_order=fourier_order, wavelength=wavelength, period=period, ucell=ucell_2d_s, thickness=thickness, type_complex=type_complex, fft_type=0, improve_dft=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (Array(0.49917828, dtype=float64), {'thickness': [Array(0.02179398, dtype=float64, weak_type=True)], 'ucell': Array([[[-0.04457337, -0.0672744 ,  0.25881959,  0.22487314,\n",
      "          0.22402433,  0.24415874, -0.01060622,  0.18296631,\n",
      "          0.09376066,  0.13521143],\n",
      "        [-0.18894426, -0.16049066,  0.15925966,  0.94591111,\n",
      "          0.98177941,  0.15896715, -0.07167921,  0.11117953,\n",
      "          0.0299822 , -0.05946715]]], dtype=float64)})\n"
     ]
    },
    {
     "ename": "UnexpectedTracerError",
     "evalue": "Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type float64[] wrapped in a JVPTracer to escape the scope of the transformation.\nJAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\nTo catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.Detail: Tracer from a higher level: Traced<ShapedArray(float64[], weak_type=True)>with<JVPTrace(level=2/1)> with\n  primal = Traced<ShapedArray(float64[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n  tangent = Traced<ShapedArray(float64[], weak_type=True)>with<JaxprTrace(level=1/1)> with\n    pval = (ShapedArray(float64[], weak_type=True), None)\n    recipe = LambdaBinding() in trace JVPTrace(level=2/1)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnexpectedTracerError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [49], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# case 2: SGD\u001B[39;00m\n\u001B[1;32m     11\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optax\u001B[38;5;241m.\u001B[39msgd(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-2\u001B[39m)\n\u001B[0;32m---> 12\u001B[0m mee\u001B[38;5;241m.\u001B[39mfit(pois, forward, loss_fn, optimizer)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;241m3\u001B[39m, mee\u001B[38;5;241m.\u001B[39mthickness\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m1E5\u001B[39m)\n",
      "File \u001B[0;32m~/project/rcwa/meent/meent/on_jax/optimizer/optimizer.py:52\u001B[0m, in \u001B[0;36mOptimizerJax.fit\u001B[0;34m(self, pois, forward, loss_fn, optimizer, iteration)\u001B[0m\n\u001B[1;32m     49\u001B[0m opt_state \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39minit(params)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(iteration):\n\u001B[0;32m---> 52\u001B[0m     params, opt_state, loss_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     54\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss_value\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "    \u001B[0;31m[... skipping hidden 18 frame]\u001B[0m\n",
      "File \u001B[0;32m~/project/rcwa/meent/meent/on_jax/optimizer/optimizer.py:40\u001B[0m, in \u001B[0;36mOptimizerJax.step\u001B[0;34m(self, params, opt_state, optimizer, forward, loss_fn)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;129m@partial\u001B[39m(jax\u001B[38;5;241m.\u001B[39mjit, static_argnums\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m))\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, params, opt_state, optimizer,  forward, loss_fn):\n\u001B[0;32m---> 40\u001B[0m     loss_value, grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m     updates, opt_state \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mupdate(grads, opt_state, params)\n\u001B[1;32m     43\u001B[0m     params \u001B[38;5;241m=\u001B[39m optax\u001B[38;5;241m.\u001B[39mapply_updates(params, updates)\n",
      "File \u001B[0;32m~/project/rcwa/meent/meent/on_jax/optimizer/optimizer.py:20\u001B[0m, in \u001B[0;36mGrad._grad\u001B[0;34m(self, params, forward, loss_fn)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_grad\u001B[39m(\u001B[38;5;28mself\u001B[39m, params, forward, loss_fn):\n\u001B[0;32m---> 20\u001B[0m     loss_value, grads \u001B[38;5;241m=\u001B[39m \u001B[43mjax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_value, grads\n",
      "    \u001B[0;31m[... skipping hidden 8 frame]\u001B[0m\n",
      "File \u001B[0;32m~/miniforge3_m1/envs/rcwa/lib/python3.9/site-packages/jax/interpreters/ad.py:88\u001B[0m, in \u001B[0;36mjvp_subtrace\u001B[0;34m(main, primals, tangents)\u001B[0m\n\u001B[1;32m     86\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, Tracer):\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39m_trace\u001B[38;5;241m.\u001B[39mlevel \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m trace\u001B[38;5;241m.\u001B[39mlevel:\n\u001B[0;32m---> 88\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39mescaped_tracer_error(\n\u001B[1;32m     89\u001B[0m           x, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTracer from a higher level: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in trace \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrace\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m x\u001B[38;5;241m.\u001B[39m_trace\u001B[38;5;241m.\u001B[39mlevel \u001B[38;5;241m<\u001B[39m trace\u001B[38;5;241m.\u001B[39mlevel\n\u001B[1;32m     91\u001B[0m in_tracers \u001B[38;5;241m=\u001B[39m [JVPTracer(trace, x, t) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(t) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m Zero \u001B[38;5;28;01melse\u001B[39;00m x\n\u001B[1;32m     92\u001B[0m               \u001B[38;5;28;01mfor\u001B[39;00m x, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(primals, tangents)]\n",
      "\u001B[0;31mUnexpectedTracerError\u001B[0m: Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type float64[] wrapped in a JVPTracer to escape the scope of the transformation.\nJAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\nTo catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.Detail: Tracer from a higher level: Traced<ShapedArray(float64[], weak_type=True)>with<JVPTrace(level=2/1)> with\n  primal = Traced<ShapedArray(float64[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n  tangent = Traced<ShapedArray(float64[], weak_type=True)>with<JaxprTrace(level=1/1)> with\n    pval = (ShapedArray(float64[], weak_type=True), None)\n    recipe = LambdaBinding() in trace JVPTrace(level=2/1)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError"
     ]
    }
   ],
   "source": [
    "pois = ['ucell', 'thickness']\n",
    "\n",
    "forward = mee.conv_solve\n",
    "loss_fn = LossDeflector(x_order=0, y_order=0)\n",
    "\n",
    "# case 1: Gradient\n",
    "grad = mee.grad(pois, forward, loss_fn)\n",
    "print(1, grad)\n",
    "\n",
    "# case 2: SGD\n",
    "optimizer = optax.sgd(learning_rate=1e-2)\n",
    "mee.fit(pois, forward, loss_fn, optimizer)\n",
    "print(3, mee.thickness*1E5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "mee = meent.call_mee(backend=backend, grating_type=grating_type, pol=pol, n_I=n_I, n_II=n_II, theta=theta, phi=phi, fourier_order=fourier_order, wavelength=wavelength, period=period, ucell=ucell_2d_s, thickness=thickness, type_complex=type_complex, fft_type=0, improve_dft=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (Array(0.49917828, dtype=float64), {'thickness': [Array(0.02179398, dtype=float64, weak_type=True)], 'ucell': Array([[[-0.04457337, -0.0672744 ,  0.25881959,  0.22487314,\n",
      "          0.22402433,  0.24415874, -0.01060622,  0.18296631,\n",
      "          0.09376066,  0.13521143],\n",
      "        [-0.18894426, -0.16049066,  0.15925966,  0.94591111,\n",
      "          0.98177941,  0.15896715, -0.07167921,  0.11117953,\n",
      "          0.0299822 , -0.05946715]]], dtype=float64)})\n"
     ]
    },
    {
     "ename": "UnexpectedTracerError",
     "evalue": "Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type float64[] wrapped in a JVPTracer to escape the scope of the transformation.\nJAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\nTo catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.Detail: Tracer from a higher level: Traced<ShapedArray(float64[], weak_type=True)>with<JVPTrace(level=2/1)> with\n  primal = Traced<ShapedArray(float64[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n  tangent = Traced<ShapedArray(float64[], weak_type=True)>with<JaxprTrace(level=1/1)> with\n    pval = (ShapedArray(float64[], weak_type=True), None)\n    recipe = LambdaBinding() in trace JVPTrace(level=2/1)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnexpectedTracerError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [49], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# case 2: SGD\u001B[39;00m\n\u001B[1;32m     11\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optax\u001B[38;5;241m.\u001B[39msgd(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-2\u001B[39m)\n\u001B[0;32m---> 12\u001B[0m mee\u001B[38;5;241m.\u001B[39mfit(pois, forward, loss_fn, optimizer)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;241m3\u001B[39m, mee\u001B[38;5;241m.\u001B[39mthickness\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m1E5\u001B[39m)\n",
      "File \u001B[0;32m~/project/rcwa/meent/meent/on_jax/optimizer/optimizer.py:52\u001B[0m, in \u001B[0;36mOptimizerJax.fit\u001B[0;34m(self, pois, forward, loss_fn, optimizer, iteration)\u001B[0m\n\u001B[1;32m     49\u001B[0m opt_state \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39minit(params)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(iteration):\n\u001B[0;32m---> 52\u001B[0m     params, opt_state, loss_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     54\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss_value\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "    \u001B[0;31m[... skipping hidden 18 frame]\u001B[0m\n",
      "File \u001B[0;32m~/project/rcwa/meent/meent/on_jax/optimizer/optimizer.py:40\u001B[0m, in \u001B[0;36mOptimizerJax.step\u001B[0;34m(self, params, opt_state, optimizer, forward, loss_fn)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;129m@partial\u001B[39m(jax\u001B[38;5;241m.\u001B[39mjit, static_argnums\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m))\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, params, opt_state, optimizer,  forward, loss_fn):\n\u001B[0;32m---> 40\u001B[0m     loss_value, grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m     updates, opt_state \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mupdate(grads, opt_state, params)\n\u001B[1;32m     43\u001B[0m     params \u001B[38;5;241m=\u001B[39m optax\u001B[38;5;241m.\u001B[39mapply_updates(params, updates)\n",
      "File \u001B[0;32m~/project/rcwa/meent/meent/on_jax/optimizer/optimizer.py:20\u001B[0m, in \u001B[0;36mGrad._grad\u001B[0;34m(self, params, forward, loss_fn)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_grad\u001B[39m(\u001B[38;5;28mself\u001B[39m, params, forward, loss_fn):\n\u001B[0;32m---> 20\u001B[0m     loss_value, grads \u001B[38;5;241m=\u001B[39m \u001B[43mjax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_value, grads\n",
      "    \u001B[0;31m[... skipping hidden 8 frame]\u001B[0m\n",
      "File \u001B[0;32m~/miniforge3_m1/envs/rcwa/lib/python3.9/site-packages/jax/interpreters/ad.py:88\u001B[0m, in \u001B[0;36mjvp_subtrace\u001B[0;34m(main, primals, tangents)\u001B[0m\n\u001B[1;32m     86\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, Tracer):\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39m_trace\u001B[38;5;241m.\u001B[39mlevel \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m trace\u001B[38;5;241m.\u001B[39mlevel:\n\u001B[0;32m---> 88\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39mescaped_tracer_error(\n\u001B[1;32m     89\u001B[0m           x, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTracer from a higher level: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in trace \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrace\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m x\u001B[38;5;241m.\u001B[39m_trace\u001B[38;5;241m.\u001B[39mlevel \u001B[38;5;241m<\u001B[39m trace\u001B[38;5;241m.\u001B[39mlevel\n\u001B[1;32m     91\u001B[0m in_tracers \u001B[38;5;241m=\u001B[39m [JVPTracer(trace, x, t) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(t) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m Zero \u001B[38;5;28;01melse\u001B[39;00m x\n\u001B[1;32m     92\u001B[0m               \u001B[38;5;28;01mfor\u001B[39;00m x, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(primals, tangents)]\n",
      "\u001B[0;31mUnexpectedTracerError\u001B[0m: Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type float64[] wrapped in a JVPTracer to escape the scope of the transformation.\nJAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\nTo catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.Detail: Tracer from a higher level: Traced<ShapedArray(float64[], weak_type=True)>with<JVPTrace(level=2/1)> with\n  primal = Traced<ShapedArray(float64[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n  tangent = Traced<ShapedArray(float64[], weak_type=True)>with<JaxprTrace(level=1/1)> with\n    pval = (ShapedArray(float64[], weak_type=True), None)\n    recipe = LambdaBinding() in trace JVPTrace(level=2/1)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError"
     ]
    }
   ],
   "source": [
    "pois = ['ucell', 'thickness']\n",
    "\n",
    "forward = mee.conv_solve\n",
    "loss_fn = LossDeflector(x_order=0, y_order=0)\n",
    "\n",
    "# case 1: Gradient\n",
    "grad = mee.grad(pois, forward, loss_fn)\n",
    "print(1, grad)\n",
    "\n",
    "# case 2: SGD\n",
    "optimizer = optax.sgd(learning_rate=1e-2)\n",
    "mee.fit(pois, forward, loss_fn, optimizer)\n",
    "print(3, mee.thickness*1E5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "mee = meent.call_mee(backend=backend, grating_type=grating_type, pol=pol, n_I=n_I, n_II=n_II, theta=theta, phi=phi, fourier_order=fourier_order, wavelength=wavelength, period=period, ucell=ucell_2d_s, thickness=thickness, type_complex=type_complex, fft_type=0, improve_dft=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (Array(0.49917828, dtype=float64), {'thickness': [Array(0.02179398, dtype=float64, weak_type=True)], 'ucell': Array([[[-0.04457337, -0.0672744 ,  0.25881959,  0.22487314,\n",
      "          0.22402433,  0.24415874, -0.01060622,  0.18296631,\n",
      "          0.09376066,  0.13521143],\n",
      "        [-0.18894426, -0.16049066,  0.15925966,  0.94591111,\n",
      "          0.98177941,  0.15896715, -0.07167921,  0.11117953,\n",
      "          0.0299822 , -0.05946715]]], dtype=float64)})\n"
     ]
    },
    {
     "ename": "UnexpectedTracerError",
     "evalue": "Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type float64[] wrapped in a JVPTracer to escape the scope of the transformation.\nJAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\nTo catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.Detail: Tracer from a higher level: Traced<ShapedArray(float64[], weak_type=True)>with<JVPTrace(level=2/1)> with\n  primal = Traced<ShapedArray(float64[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n  tangent = Traced<ShapedArray(float64[], weak_type=True)>with<JaxprTrace(level=1/1)> with\n    pval = (ShapedArray(float64[], weak_type=True), None)\n    recipe = LambdaBinding() in trace JVPTrace(level=2/1)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnexpectedTracerError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [49], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# case 2: SGD\u001B[39;00m\n\u001B[1;32m     11\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optax\u001B[38;5;241m.\u001B[39msgd(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-2\u001B[39m)\n\u001B[0;32m---> 12\u001B[0m mee\u001B[38;5;241m.\u001B[39mfit(pois, forward, loss_fn, optimizer)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;241m3\u001B[39m, mee\u001B[38;5;241m.\u001B[39mthickness\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m1E5\u001B[39m)\n",
      "File \u001B[0;32m~/project/rcwa/meent/meent/on_jax/optimizer/optimizer.py:52\u001B[0m, in \u001B[0;36mOptimizerJax.fit\u001B[0;34m(self, pois, forward, loss_fn, optimizer, iteration)\u001B[0m\n\u001B[1;32m     49\u001B[0m opt_state \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39minit(params)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(iteration):\n\u001B[0;32m---> 52\u001B[0m     params, opt_state, loss_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     54\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss_value\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "    \u001B[0;31m[... skipping hidden 18 frame]\u001B[0m\n",
      "File \u001B[0;32m~/project/rcwa/meent/meent/on_jax/optimizer/optimizer.py:40\u001B[0m, in \u001B[0;36mOptimizerJax.step\u001B[0;34m(self, params, opt_state, optimizer, forward, loss_fn)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;129m@partial\u001B[39m(jax\u001B[38;5;241m.\u001B[39mjit, static_argnums\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m))\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, params, opt_state, optimizer,  forward, loss_fn):\n\u001B[0;32m---> 40\u001B[0m     loss_value, grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m     updates, opt_state \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mupdate(grads, opt_state, params)\n\u001B[1;32m     43\u001B[0m     params \u001B[38;5;241m=\u001B[39m optax\u001B[38;5;241m.\u001B[39mapply_updates(params, updates)\n",
      "File \u001B[0;32m~/project/rcwa/meent/meent/on_jax/optimizer/optimizer.py:20\u001B[0m, in \u001B[0;36mGrad._grad\u001B[0;34m(self, params, forward, loss_fn)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_grad\u001B[39m(\u001B[38;5;28mself\u001B[39m, params, forward, loss_fn):\n\u001B[0;32m---> 20\u001B[0m     loss_value, grads \u001B[38;5;241m=\u001B[39m \u001B[43mjax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_value, grads\n",
      "    \u001B[0;31m[... skipping hidden 8 frame]\u001B[0m\n",
      "File \u001B[0;32m~/miniforge3_m1/envs/rcwa/lib/python3.9/site-packages/jax/interpreters/ad.py:88\u001B[0m, in \u001B[0;36mjvp_subtrace\u001B[0;34m(main, primals, tangents)\u001B[0m\n\u001B[1;32m     86\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, Tracer):\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39m_trace\u001B[38;5;241m.\u001B[39mlevel \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m trace\u001B[38;5;241m.\u001B[39mlevel:\n\u001B[0;32m---> 88\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39mescaped_tracer_error(\n\u001B[1;32m     89\u001B[0m           x, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTracer from a higher level: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in trace \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrace\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m x\u001B[38;5;241m.\u001B[39m_trace\u001B[38;5;241m.\u001B[39mlevel \u001B[38;5;241m<\u001B[39m trace\u001B[38;5;241m.\u001B[39mlevel\n\u001B[1;32m     91\u001B[0m in_tracers \u001B[38;5;241m=\u001B[39m [JVPTracer(trace, x, t) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(t) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m Zero \u001B[38;5;28;01melse\u001B[39;00m x\n\u001B[1;32m     92\u001B[0m               \u001B[38;5;28;01mfor\u001B[39;00m x, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(primals, tangents)]\n",
      "\u001B[0;31mUnexpectedTracerError\u001B[0m: Encountered an unexpected tracer. A function transformed by JAX had a side effect, allowing for a reference to an intermediate value with type float64[] wrapped in a JVPTracer to escape the scope of the transformation.\nJAX transformations require that functions explicitly return their outputs, and disallow saving intermediate values to global state.\nTo catch the leak earlier, try setting the environment variable JAX_CHECK_TRACER_LEAKS or using the `jax.checking_leaks` context manager.Detail: Tracer from a higher level: Traced<ShapedArray(float64[], weak_type=True)>with<JVPTrace(level=2/1)> with\n  primal = Traced<ShapedArray(float64[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n  tangent = Traced<ShapedArray(float64[], weak_type=True)>with<JaxprTrace(level=1/1)> with\n    pval = (ShapedArray(float64[], weak_type=True), None)\n    recipe = LambdaBinding() in trace JVPTrace(level=2/1)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError"
     ]
    }
   ],
   "source": [
    "pois = ['ucell', 'thickness']\n",
    "\n",
    "forward = mee.conv_solve\n",
    "loss_fn = LossDeflector(x_order=0, y_order=0)\n",
    "\n",
    "# case 1: Gradient\n",
    "grad = mee.grad(pois, forward, loss_fn)\n",
    "print(1, grad)\n",
    "\n",
    "# case 2: SGD\n",
    "optimizer = optax.sgd(learning_rate=1e-2)\n",
    "mee.fit(pois, forward, loss_fn, optimizer)\n",
    "print(3, mee.thickness*1E5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
