{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Meent Tutorial 2\n",
    "## PyTorch: Gradient and Optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import meent\n",
    "from meent.on_torch.optimizer.loss import LossDeflector\n",
    "from meent.on_torch.optimizer.optimizer import OptimizerTorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "backend = 2  # Torch\n",
    "\n",
    "# common\n",
    "pol = 0  # 0: TE, 1: TM\n",
    "\n",
    "n_I = 1  # n_incidence\n",
    "n_II = 1  # n_transmission\n",
    "\n",
    "theta = 0 * torch.pi / 180\n",
    "phi = 0 * torch.pi / 180\n",
    "\n",
    "wavelength = 900\n",
    "\n",
    "thickness = torch.tensor([500., 1000.])\n",
    "period = torch.tensor([1000.])\n",
    "\n",
    "fourier_order = [10]\n",
    "\n",
    "type_complex = torch.complex128\n",
    "device = torch.device('cpu')\n",
    "\n",
    "grating_type = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "ucell_1d_m = torch.tensor([\n",
    "    [[0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ]],\n",
    "    [[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, ]],\n",
    "    ]) * 4 + 1.  # refractive index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Gradient\n",
    "Gradient can be calculated with the help of `torch.autograd` function.\n",
    "Read this for further information: [A GENTLE INTRODUCTION TO TORCH.AUTOGRAD](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)\n",
    "\n",
    "Gradient can be utilized to solve optimization problems. Here some examples show couple of ways to get gradient or optimized values with or without predefined functions of meent."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.1 case 1\n",
    "manually get gradient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ucell gradient:\n",
      "tensor([[[-0.0512, -0.0253, -0.0073,  0.0787, -0.0184,  0.0945,  0.0878,\n",
      "          -0.0012, -0.0364, -0.0478]],\n",
      "\n",
      "        [[-0.1795, -0.0860, -0.2223, -0.1938,  0.0899,  0.0558, -0.0456,\n",
      "          -0.1359, -0.2983,  0.1288]]])\n",
      "thickness gradient:\n",
      "tensor([ 0.0022, -0.0067])\n"
     ]
    }
   ],
   "source": [
    "mee = meent.call_mee(backend=backend, grating_type=grating_type, pol=pol, n_I=n_I, n_II=n_II, theta=theta, phi=phi, fourier_order=fourier_order, wavelength=wavelength, period=period, ucell=ucell_1d_m, thickness=thickness, type_complex=type_complex, device=device, fft_type=0, improve_dft=True)\n",
    "\n",
    "mee.ucell.requires_grad = True\n",
    "mee.thickness.requires_grad = True\n",
    "\n",
    "de_ri, de_ti = mee.conv_solve()\n",
    "loss = de_ti[de_ti.shape[0] // 2 + 1]\n",
    "\n",
    "loss.backward()\n",
    "print('ucell gradient:')\n",
    "print(mee.ucell.grad)\n",
    "print('thickness gradient:')\n",
    "print(mee.thickness.grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.2 case 2\n",
    "using predefined 'grad' function in meent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ucell gradient:\n",
      "tensor([[[-0.0512, -0.0253, -0.0073,  0.0787, -0.0184,  0.0945,  0.0878,\n",
      "          -0.0012, -0.0364, -0.0478]],\n",
      "\n",
      "        [[-0.1795, -0.0860, -0.2223, -0.1938,  0.0899,  0.0558, -0.0456,\n",
      "          -0.1359, -0.2983,  0.1288]]])\n",
      "thickness gradient:\n",
      "tensor([ 0.0022, -0.0067])\n"
     ]
    }
   ],
   "source": [
    "mee = meent.call_mee(backend=backend, grating_type=grating_type, pol=pol, n_I=n_I, n_II=n_II, theta=theta, phi=phi, fourier_order=fourier_order, wavelength=wavelength, period=period, ucell=ucell_1d_m, thickness=thickness, type_complex=type_complex, device=device, fft_type=0, improve_dft=True)\n",
    "\n",
    "pois = ['ucell', 'thickness']  # Parameter Of Interests\n",
    "\n",
    "forward = mee.conv_solve\n",
    "\n",
    "# can use custom loss function or predefined loss function in meent.\n",
    "\n",
    "# loss_fn = LossDeflector(x_order=1)  # predefined in meent\n",
    "loss_fn = lambda x: x[1][x[1].shape[0] // 2 + 1]  # custom\n",
    "\n",
    "grad = mee.grad(pois, forward, loss_fn)\n",
    "print('ucell gradient:')\n",
    "print(grad['ucell'])\n",
    "print('thickness gradient:')\n",
    "print(grad['thickness'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2.1 case 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0291, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0267, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0235, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0185, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0140, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0092, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0057, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0035, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0008, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0030, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0033, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0029, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0017, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0005, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0002, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0001, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(5.9356e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(4.1234e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(8.5686e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0002, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0003, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0003, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0003, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0003, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0002, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0002, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0001, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0001, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(7.1445e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(4.1615e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.9905e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(7.8283e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.7840e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(4.0656e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(5.8130e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(8.7932e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.3906e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.0892e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.7999e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.3110e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.5553e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.5886e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.5233e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.3976e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.1760e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.8127e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.3452e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.8604e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.4347e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.0843e-05, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(7.8088e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(5.0959e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.8024e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.1883e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.8119e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.2172e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(4.0573e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(6.7205e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.0007e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.4350e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.9961e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.5642e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.9986e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.1941e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.2061e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3.1088e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.9616e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.7601e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.4720e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.0923e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.6820e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.2897e-06, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(9.6543e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(7.0426e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(4.7702e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.8385e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.3356e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(4.1108e-08, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(9.2360e-09, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.0376e-08, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(4.9618e-08, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(8.4772e-08, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.1844e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(1.6130e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.0675e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.4959e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.7478e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.8069e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.7343e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(2.5855e-07, dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mee = meent.call_mee(backend=backend, grating_type=grating_type, pol=pol, n_I=n_I, n_II=n_II, theta=theta, phi=phi, fourier_order=fourier_order, wavelength=wavelength, period=period, ucell=ucell_1d_m, thickness=thickness, type_complex=type_complex, device=device, fft_type=0, improve_dft=True)\n",
    "\n",
    "mee.ucell.requires_grad = True\n",
    "mee.thickness.requires_grad = True\n",
    "opt = torch.optim.SGD([mee.ucell, mee.thickness], lr=1E-2, momentum=0.9)\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    de_ri, de_ti = mee.conv_solve()\n",
    "\n",
    "    center = de_ti.shape[0] // 2\n",
    "    loss = de_ti[center + 1]\n",
    "\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2.2 case 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 0.029141591152553024\n",
      "step 1, loss: 0.026655024513172282\n",
      "step 2, loss: 0.02348784876570143\n",
      "step 3, loss: 0.018518856342830476\n",
      "step 4, loss: 0.014045038431714268\n",
      "step 5, loss: 0.009240928804785936\n",
      "step 6, loss: 0.005675249611651967\n",
      "step 7, loss: 0.0035335352418931344\n",
      "step 8, loss: 0.0018367942977096337\n",
      "step 9, loss: 0.0007733766260211415\n",
      "step 10, loss: 0.001228100591650995\n",
      "step 11, loss: 0.0023393996402068327\n",
      "step 12, loss: 0.0029773505075635716\n",
      "step 13, loss: 0.0033075310517868732\n",
      "step 14, loss: 0.0029168526201331017\n",
      "step 15, loss: 0.002292950201690544\n",
      "step 16, loss: 0.0016667459159062903\n",
      "step 17, loss: 0.0010469976100209674\n",
      "step 18, loss: 0.0005248982259839158\n",
      "step 19, loss: 0.00021465831290599008\n",
      "step 20, loss: 0.00010435964182362401\n",
      "step 21, loss: 5.935564914121781e-05\n",
      "step 22, loss: 4.123373181406379e-05\n",
      "step 23, loss: 8.568562465758101e-05\n",
      "step 24, loss: 0.00017595533399906548\n",
      "step 25, loss: 0.00026939594800027183\n",
      "step 26, loss: 0.00033817415116938675\n",
      "step 27, loss: 0.00037746346769935654\n",
      "step 28, loss: 0.00039602390845884495\n",
      "step 29, loss: 0.00040296427945001593\n",
      "step 30, loss: 0.00039895031617558297\n",
      "step 31, loss: 0.00037824885514301394\n",
      "step 32, loss: 0.0003384964572750233\n",
      "step 33, loss: 0.00028665528396026017\n",
      "step 34, loss: 0.00023365698455312964\n",
      "step 35, loss: 0.00018603011533770925\n",
      "step 36, loss: 0.0001442091162669635\n",
      "step 37, loss: 0.00010628129601703015\n",
      "step 38, loss: 7.144542285730304e-05\n",
      "step 39, loss: 4.1615242997769666e-05\n",
      "step 40, loss: 1.9905041355119727e-05\n",
      "step 41, loss: 7.828338987045e-06\n",
      "step 42, loss: 3.7839759790896054e-06\n",
      "step 43, loss: 4.065619626954479e-06\n",
      "step 44, loss: 5.812976593322399e-06\n",
      "step 45, loss: 8.793150006742081e-06\n",
      "step 46, loss: 1.3906452515820515e-05\n",
      "step 47, loss: 2.089209783180359e-05\n",
      "step 48, loss: 2.799879914145444e-05\n",
      "step 49, loss: 3.31103356307106e-05\n",
      "step 50, loss: 3.555266855412508e-05\n",
      "step 51, loss: 3.588630531046729e-05\n",
      "step 52, loss: 3.523342091715115e-05\n",
      "step 53, loss: 3.397556600429516e-05\n",
      "step 54, loss: 3.175953031922079e-05\n",
      "step 55, loss: 2.81270207496655e-05\n",
      "step 56, loss: 2.345189123062391e-05\n",
      "step 57, loss: 1.8603699766082906e-05\n",
      "step 58, loss: 1.4347363160313812e-05\n",
      "step 59, loss: 1.0843460209687161e-05\n",
      "step 60, loss: 7.808807945364368e-06\n",
      "step 61, loss: 5.095875418575726e-06\n",
      "step 62, loss: 2.8024256915141255e-06\n",
      "step 63, loss: 1.1882757960782466e-06\n",
      "step 64, loss: 3.8119026350190094e-07\n",
      "step 65, loss: 2.2171753777351783e-07\n",
      "step 66, loss: 4.057328683290171e-07\n",
      "step 67, loss: 6.720487823078904e-07\n",
      "step 68, loss: 1.0006606487188974e-06\n",
      "step 69, loss: 1.4349615908171935e-06\n",
      "step 70, loss: 1.996087155932955e-06\n",
      "step 71, loss: 2.564223671490106e-06\n",
      "step 72, loss: 2.9986206421734627e-06\n",
      "step 73, loss: 3.194053001396106e-06\n",
      "step 74, loss: 3.2060668883679035e-06\n",
      "step 75, loss: 3.1087872858548254e-06\n",
      "step 76, loss: 2.961641942860738e-06\n",
      "step 77, loss: 2.7601237084158446e-06\n",
      "step 78, loss: 2.471992770216254e-06\n",
      "step 79, loss: 2.092332474053973e-06\n",
      "step 80, loss: 1.6820152852644014e-06\n",
      "step 81, loss: 1.2897257501076519e-06\n",
      "step 82, loss: 9.654291168242338e-07\n",
      "step 83, loss: 7.042577315094798e-07\n",
      "step 84, loss: 4.77019150365357e-07\n",
      "step 85, loss: 2.8384662030184904e-07\n",
      "step 86, loss: 1.3356143281863928e-07\n",
      "step 87, loss: 4.1108251765611294e-08\n",
      "step 88, loss: 9.236004127381206e-09\n",
      "step 89, loss: 2.0375582516621203e-08\n",
      "step 90, loss: 4.9617740580232066e-08\n",
      "step 91, loss: 8.477162447329817e-08\n",
      "step 92, loss: 1.1843970335852128e-07\n",
      "step 93, loss: 1.612962599916789e-07\n",
      "step 94, loss: 2.0675490137528783e-07\n",
      "step 95, loss: 2.4959054443850505e-07\n",
      "step 96, loss: 2.747773100446934e-07\n",
      "step 97, loss: 2.806912337277149e-07\n",
      "step 98, loss: 2.734259213696351e-07\n",
      "step 99, loss: 2.585488137386653e-07\n"
     ]
    }
   ],
   "source": [
    "mee = meent.call_mee(backend=backend, grating_type=grating_type, pol=pol, n_I=n_I, n_II=n_II, theta=theta, phi=phi, fourier_order=fourier_order, wavelength=wavelength, period=period, ucell=ucell_1d_m, thickness=thickness, type_complex=type_complex, device=device, fft_type=0, improve_dft=True)\n",
    "\n",
    "\n",
    "def forward_fn():\n",
    "\n",
    "    de_ri, de_ti = mee.conv_solve()\n",
    "\n",
    "    center = de_ti.shape[0] // 2\n",
    "    loss = de_ti[center + 1]\n",
    "    return loss\n",
    "\n",
    "pois = ['ucell', 'thickness']\n",
    "forward = forward_fn\n",
    "loss_fn = lambda x: x\n",
    "opt_torch = torch.optim.SGD\n",
    "opt_options = {'lr': 1E-2,\n",
    "               'momentum': 0.9,\n",
    "               }\n",
    "\n",
    "mee.fit(pois, forward, loss_fn, opt_torch, opt_options)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 0.029141591152553024\n",
      "step 1, loss: 0.026655024513172282\n",
      "step 2, loss: 0.02348784876570143\n",
      "step 3, loss: 0.018518856342830476\n",
      "step 4, loss: 0.014045038431714268\n",
      "step 5, loss: 0.009240928804785936\n",
      "step 6, loss: 0.005675249611651967\n",
      "step 7, loss: 0.0035335352418931344\n",
      "step 8, loss: 0.0018367942977096337\n",
      "step 9, loss: 0.0007733766260211415\n",
      "step 10, loss: 0.001228100591650995\n",
      "step 11, loss: 0.0023393996402068327\n",
      "step 12, loss: 0.0029773505075635716\n",
      "step 13, loss: 0.0033075310517868732\n",
      "step 14, loss: 0.0029168526201331017\n",
      "step 15, loss: 0.002292950201690544\n",
      "step 16, loss: 0.0016667459159062903\n",
      "step 17, loss: 0.0010469976100209674\n",
      "step 18, loss: 0.0005248982259839158\n",
      "step 19, loss: 0.00021465831290599008\n",
      "step 20, loss: 0.00010435964182362401\n",
      "step 21, loss: 5.935564914121781e-05\n",
      "step 22, loss: 4.123373181406379e-05\n",
      "step 23, loss: 8.568562465758101e-05\n",
      "step 24, loss: 0.00017595533399906548\n",
      "step 25, loss: 0.00026939594800027183\n",
      "step 26, loss: 0.00033817415116938675\n",
      "step 27, loss: 0.00037746346769935654\n",
      "step 28, loss: 0.00039602390845884495\n",
      "step 29, loss: 0.00040296427945001593\n",
      "step 30, loss: 0.00039895031617558297\n",
      "step 31, loss: 0.00037824885514301394\n",
      "step 32, loss: 0.0003384964572750233\n",
      "step 33, loss: 0.00028665528396026017\n",
      "step 34, loss: 0.00023365698455312964\n",
      "step 35, loss: 0.00018603011533770925\n",
      "step 36, loss: 0.0001442091162669635\n",
      "step 37, loss: 0.00010628129601703015\n",
      "step 38, loss: 7.144542285730304e-05\n",
      "step 39, loss: 4.1615242997769666e-05\n",
      "step 40, loss: 1.9905041355119727e-05\n",
      "step 41, loss: 7.828338987045e-06\n",
      "step 42, loss: 3.7839759790896054e-06\n",
      "step 43, loss: 4.065619626954479e-06\n",
      "step 44, loss: 5.812976593322399e-06\n",
      "step 45, loss: 8.793150006742081e-06\n",
      "step 46, loss: 1.3906452515820515e-05\n",
      "step 47, loss: 2.089209783180359e-05\n",
      "step 48, loss: 2.799879914145444e-05\n",
      "step 49, loss: 3.31103356307106e-05\n",
      "step 50, loss: 3.555266855412508e-05\n",
      "step 51, loss: 3.588630531046729e-05\n",
      "step 52, loss: 3.523342091715115e-05\n",
      "step 53, loss: 3.397556600429516e-05\n",
      "step 54, loss: 3.175953031922079e-05\n",
      "step 55, loss: 2.81270207496655e-05\n",
      "step 56, loss: 2.345189123062391e-05\n",
      "step 57, loss: 1.8603699766082906e-05\n",
      "step 58, loss: 1.4347363160313812e-05\n",
      "step 59, loss: 1.0843460209687161e-05\n",
      "step 60, loss: 7.808807945364368e-06\n",
      "step 61, loss: 5.095875418575726e-06\n",
      "step 62, loss: 2.8024256915141255e-06\n",
      "step 63, loss: 1.1882757960782466e-06\n",
      "step 64, loss: 3.8119026350190094e-07\n",
      "step 65, loss: 2.2171753777351783e-07\n",
      "step 66, loss: 4.057328683290171e-07\n",
      "step 67, loss: 6.720487823078904e-07\n",
      "step 68, loss: 1.0006606487188974e-06\n",
      "step 69, loss: 1.4349615908171935e-06\n",
      "step 70, loss: 1.996087155932955e-06\n",
      "step 71, loss: 2.564223671490106e-06\n",
      "step 72, loss: 2.9986206421734627e-06\n",
      "step 73, loss: 3.194053001396106e-06\n",
      "step 74, loss: 3.2060668883679035e-06\n",
      "step 75, loss: 3.1087872858548254e-06\n",
      "step 76, loss: 2.961641942860738e-06\n",
      "step 77, loss: 2.7601237084158446e-06\n",
      "step 78, loss: 2.471992770216254e-06\n",
      "step 79, loss: 2.092332474053973e-06\n",
      "step 80, loss: 1.6820152852644014e-06\n",
      "step 81, loss: 1.2897257501076519e-06\n",
      "step 82, loss: 9.654291168242338e-07\n",
      "step 83, loss: 7.042577315094798e-07\n",
      "step 84, loss: 4.77019150365357e-07\n",
      "step 85, loss: 2.8384662030184904e-07\n",
      "step 86, loss: 1.3356143281863928e-07\n",
      "step 87, loss: 4.1108251765611294e-08\n",
      "step 88, loss: 9.236004127381206e-09\n",
      "step 89, loss: 2.0375582516621203e-08\n",
      "step 90, loss: 4.9617740580232066e-08\n",
      "step 91, loss: 8.477162447329817e-08\n",
      "step 92, loss: 1.1843970335852128e-07\n",
      "step 93, loss: 1.612962599916789e-07\n",
      "step 94, loss: 2.0675490137528783e-07\n",
      "step 95, loss: 2.4959054443850505e-07\n",
      "step 96, loss: 2.747773100446934e-07\n",
      "step 97, loss: 2.806912337277149e-07\n",
      "step 98, loss: 2.734259213696351e-07\n",
      "step 99, loss: 2.585488137386653e-07\n"
     ]
    }
   ],
   "source": [
    "mee = meent.call_mee(backend=backend, grating_type=grating_type, pol=pol, n_I=n_I, n_II=n_II, theta=theta, phi=phi, fourier_order=fourier_order, wavelength=wavelength, period=period, ucell=ucell_1d_m, thickness=thickness, type_complex=type_complex, device=device, fft_type=0, improve_dft=True)\n",
    "\n",
    "pois = ['ucell', 'thickness']\n",
    "\n",
    "forward = mee.conv_solve\n",
    "loss_fn = LossDeflector(1, 0)\n",
    "\n",
    "opt_torch = torch.optim.SGD\n",
    "opt_options = {'lr': 1E-2,\n",
    "               'momentum': 0.9,\n",
    "               }\n",
    "\n",
    "mee.fit(pois, forward, loss_fn, opt_torch, opt_options)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
